# Evaluation Plan

## Goals
Evaluate whether CodeOnBoard improves onboarding effectiveness.

---

## Metrics
- Time to complete first meaningful task
- Number of clarification questions
- User-reported confidence
- Task success rate

---

## Baseline Comparison

The evaluation of CodeOnBoard will be conducted against two realistic baselines:

1. Manual onboarding through reading README files and project documentation.
   This represents the traditional onboarding process, where developers independently explore the codebase without structured task prioritization or guided learning paths.

2. AI-assisted development using tools such as GitHub Copilot or Cursor.
   These tools provide strong contextual explanations and code-level assistance within the IDE.
   However, they are primarily reactive and do not explicitly manage onboarding as a task-driven, multi-stage process with global prioritization, learning objectives, and progress tracking.

This comparison aims to evaluate whether modeling onboarding as a first-class, goal-oriented process provides additional value beyond existing AI coding assistants.


---

## Expected Outcome
Users reach contribution-ready understanding faster with CodeOnBoard.
